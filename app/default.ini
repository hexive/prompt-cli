#################
# user_config.ini
# you can change some default options

[search]
# if you run qdrant at different ip address or use a different port
qdrant_url = http://localhost:6333

# this is a public dataset of promps mostly from civitai so it's very NSFW / NSFL. if you want to tone that down a little you can use a blocklist which will filter searches to exclude keywords (this list was made by llama70b haha) edit blocklist.txt one word or phrase per line.
use_blocklist = false

# prompt-cli can start qdrant for you at launch the full run command used is (docker run -p 6333:6333 -p 6334:6334 -v qdrant_storage:/qdrant/storage:z -e QDRANT__TELEMETRY_DISABLED=true qdrant/qdrant) if you need to modify that its at prompt-cli/app/preflight.py start_qdrant()
qdrant_start = false

[llm]
# these are Llama.cpp settings from the API. If you need to add others look in /app/llm.py get_model()

# I like this model (mistral) because it has a massive context size but that also eats VRAM so if you need to, you can adjust the context to best suit your VRAM n_ctx. should be adjusted to largest your GPU can handle for better results. some valid numbers in the usual ranges 4096,8192,16384,32768
n_ctx=8192

# another way to lower VRAM usage is to decrease the number of gpu layers used. -1 means use all layers. this model has 33 layers
n_gpu_layers=-1

# these you can ignore if you don't have multiple gpu. split mode 1 is equally split model across gpus 0 is don't split. main_gpu is just which one to use if it's not split
split_mode=1 
main_gpu=0

# true turns on all the llama.cpp feedback when loading the model and the token count for each response. ugly, but useful for debuging
verbose=false

# this is the llm prompt that the llm will use with /new to create the stable-diffusion image from context. It has to be one big line with no breaks for this config parser to understand it.
image_prompt="Create an image prompt based on the CONTEXT: provided. when creating the image prompt, use the PROMPT PYRAMID method outlined here. THE PROMPT PYRAMID (Base of the Pyramid) Medium: Define the base medium of the image (e.g., photograph, oil painting, vector illustration, etc.).This should be whatever majority of prompts in context are. Subject: Describe the main subject of your image. For people, include details such as age, complexion, etc. Activity: Describe the activity happening in the image. Include a general pose, as well as a specific action that the subject is doing. Setting: Set the scene where the image takes place, with some interesting visual details. Wardrobe: Detail the clothing or costume elements in the image, if applicable. Lighting: Specify the type of lighting and shadows in the image. Vibe: Convey the overall mood or atmosphere of the image. Added stylistic details: Add comma separated specific keywords at the end that might enhance the image's quality or make the image more interesting. This includes camera framing, film stocks, focal length, tone, etc. Use your creativity here. Just add these to the end of the promptâ€”no label necessary. (Point of the Pyramid) Example: A portrait photo of an old man baking a cake in a rustic kitchen. He is wearing a white button down shirt with a worn apron, dusted with flour. The kitchen is dimly lit, with shelves lined with cooking utensils. Morning light streams in from a nearby window, casting soft shadows. The scene is calm and welcoming. Underexposed, vignette, matte finish. Remember to ANSWER: with only 1 prompt and with the prompt text only "

[image]

# if you run stable-diffusion-webui at different ip address or use a different port
image-gen_url = http://localhost:7860

# image width and height for stable-diffusion generation
gen_img_width=768
gen_img_height=1024

# thumbnail maximum width and height for image displayed in console. resize will keep aspect ratio and only shrink if larger than one of the numbers
thumb_img_max_width=768
thum_img_max_height=512

# diffusion sampler to use. you can change model checkpoint in-app.
sampler_name = DPM++ 2M

# true saves all images generated to prompt-cli/output/ folder
save_images_app = false

# true saves all images generated to stable-diffusion-webui/output/ folder
save_images_api = false

# prompt-cli can start stable-diffusion for you at launch update with full path to the stable-diffusions webui.sh including any launch flags you'd like. --api is required
stable_diffusion_start = false
stable_diffusion_path = /home/your/full/path/to/stable-diffusion-webui/webui.sh --listen --api

[ui]
#16 colors is all you'll ever need! valid names: black, red, green, yellow, blue, magenta, cyan, white, bright_black, bright_red, bright_green, bright_yellow, bright_blue, bright_magenta, bright_cyan, bright_white
app_color = blue
search_color = cyan
llm_color = green
error_color = red

# turns on some exception tracebacks and other things that are useful for troubleshooting.
debug = false
